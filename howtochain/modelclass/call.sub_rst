層の使用方法の記述
---------------------

使う層の定義を書いたので、次は層をどのような順番で呼び出すのかを書いていきます。

入力をxとして以下のような関数をクラスの中に追加しましょう。

.. code-block:: python

    def __call__(self, x):
        h1 = self.l1(x)
        h2 = self.l2(h1)
        y = self.l3(h2)
        return y

このままでも学習することは可能ですが、通常は層の出力に活性化関数を適用します。

今回は活性化関数にReLU関数というものを用いてみます。例のごとく、Chainerには予めchainer.functionsに活性化関数などの定義がなされているため、これを活用します。

各層の出力にReLU関数を適用していきます。このとき出力yにはReLU関数をはさまないことに注意してください。

.. code-block:: python

    ...
    import chainer.functions as F

    def __call__(self, x):
        h1 = F.relu(self.l1(x))
        h2 = F.relu(self.l2(h1))
        y = self.l3(h2) # 最後は出力のためReLU関数は追加しなくていい。
        return y

.. column:: 恒等関数

    実は最初の状態、活性関数を適用していない用に見える状態でも、恒等関数という値をそのまま返すという関数を適用しているのと同じになります。

    恒等関数は :math:`f(x)=x` で表されます。

.. column:: ReLU関数について

    ReLU関数は入力をxとして max(0,x) を出力する関数です。そのため取る値は0以上の値になるため、

    最終的な出力が実数全体を対象とする場合を考慮して、最後だけReLU関数を追加しません。

ここまででモデルクラスを構成することが出来ました。

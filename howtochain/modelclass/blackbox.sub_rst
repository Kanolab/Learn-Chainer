ニューラルネットワークの仕組み
---------------------------------

始めにニューラルネットワークは何らかの関数を近似した推論機を作り出すことと言いました。

では推論機はどのように関数を近似しているのでしょうか。それについてはニューラルネットワークの仕組みについて理解する必要があります。

ニューラルネットワークの推論器は始めの入力の後に連なるように関数が連続したもので成り立っています。

.. figure:: nn_image.png

    ニューラルネットワークは複数の関数が連なって構成されている。

始めの入力やこういった関数やその出力をニューラルネットワークでは層と言います。また出力は基本的には配列の形であるため、それぞれの要素のことをユニット(Unit)と呼びます。

とくに始めの入力については入力層、推論器の一番最後の関数とその出力については出力層、それ以外のものは隠れ層と言います。

.. raw:: latex

    \clearpage

また層の間には層とは別のものとして活性化関数と呼ばれる、ユニットひとつひとつに対して適用する関数があります。ここで層はユニットすべてを引数に取り、
そこから新たに（もしかしたら異なる数かもしれない）ユニットを出力するという活性化関数との違いに注意してください。

.. figure:: nn_activate_image.png

    層と層の間には活性化関数と呼ばれるそれぞれのユニットに適用される関数がある。

最後にニューラルネットワークの性能を評価し推論器の学習を進めるために損失関数（または誤差関数）というものが使われます。

損失関数はニューラルネットワークがどれだけ目的の関数に近似できたかを評価するものです。

この損失関数には大きく分けて3つの種類があります。ひとつ目は :math:`f(x)=2x` のような実数を解として持つもので、これは回帰(Regression)と呼ばれます。

さらに回帰に加えて、そうでないかそうであるかを分類する二値分類、と2つ以上のクラスに分類をする多クラス分類（Classification)があります。